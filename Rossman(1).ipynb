{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import ctypes\n",
    "import copy\n",
    "import sys\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import coo_matrix, hstack, csr_matrix, vstack\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from pyfm import pylibfm\n",
    "# from adaboost_multiple import AdaBoost\n",
    "from itertools import combinations\n",
    "from sklearn import metrics, cross_validation, linear_model\n",
    "# from logistic_regression_updated import group_data,OneHotEncoder2\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n",
    "            index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(filetrain,filetest,filestore):\n",
    "    '''Function to load train and test data into pandas data frame. \n",
    "    Argument1 : training dataset filename\n",
    "    Argument2 : test dataset filename\n",
    "    '''\n",
    "    train_df = pd.read_csv(filetrain, header=0)\n",
    "    test_df = pd.read_csv(filetest, header=0)\n",
    "    store_df = pd.read_csv(filestore, header=0)\n",
    "\n",
    "    return train_df, test_df, store_df\n",
    "\n",
    "train_df, test_df, store_df = load_data('train.csv','test.csv','store.csv')\n",
    "train_df = train_df.merge(right = store_df, how = 'inner', on = 'Store')\n",
    "test_df = test_df.merge(right = store_df, how = 'inner', on = 'Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['Date'] = train_df['Date'].map(lambda x : datetime.strptime(x, '%Y-%m-%d'))\n",
    "test_df['Date'] = test_df['Date'].map(lambda x : datetime.strptime(x, '%Y-%m-%d'))\n",
    "train_df['Year'] = train_df['Date'].map(lambda x : int(x.year))\n",
    "train_df['Month'] = train_df['Date'].map(lambda x : int(x.month))\n",
    "test_df['Year'] = test_df['Date'].map(lambda x : int(x.year))\n",
    "test_df['Month'] = test_df['Date'].map(lambda x : int(x.month))\n",
    "test_df = test_df[[col for col in test_df.columns if col not in ['Date']]]\n",
    "train_df = train_df[[col for col in train_df.columns if col not in ['Date']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = train_df[[col for col in train_df.columns if col not in ['Customers','Sales']]]\n",
    "test_X = test_df\n",
    "train_Y = train_df['Sales']\n",
    "Big_X = train_X.append(test_X)\n",
    "Big_Imputed = DataFrameImputer().fit_transform(Big_X)\n",
    "train_X = Big_Imputed.iloc[0:len(train_df)]\n",
    "test_X = Big_Imputed.iloc[len(train_df):len(Big_Imputed)]\n",
    "train_X = train_X[[col for col in train_X.columns if col not in ['Id']]]\n",
    "test_X = test_X[[col for col in test_X.columns if col not in ['Id']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_num(df, column):\n",
    "    x = np.unique(df[column])\n",
    "    dic = {}\n",
    "    count = 0\n",
    "    for i in range(len(x)):\n",
    "        dic[x[i]] = i\n",
    "    df[column] = df[column].map(lambda x : dic[x])\n",
    "    return df\n",
    "\n",
    "Big_X = train_X.append(test_X)\n",
    "\n",
    "Big_X = convert_to_num(Big_X, 'Assortment')\n",
    "Big_X = convert_to_num(Big_X, 'PromoInterval')\n",
    "Big_X = convert_to_num(Big_X, 'StoreType')\n",
    "Big_X = convert_to_num(Big_X, 'StateHoliday')\n",
    "train_X = Big_X.iloc[0:len(train_df)]\n",
    "test_X = Big_X.iloc[len(train_df):len(Big_X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Simple XGB\n",
    "# gbm = xgb.XGBRegressor().fit(train_X.as_matrix(), train_Y.as_matrix())\n",
    "# param_test1 = {'max_depth':range(6,13,3),'n_estimators' : [100,200], 'colsample_bytree' : [0.4,0.8]}\n",
    "# gsearch1 = GridSearchCV(estimator = xgb.XGBRegressor(learning_rate =0.05, n_estimators=300, max_depth=5,min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,scale_pos_weight=1, seed=11), param_grid = param_test1,n_jobs=20,iid=False, cv=5)\n",
    "# gsearch1.fit(train_X,train_Y)\n",
    "# bp = gsearch1.best_params_\n",
    "# print bp\n",
    "prediction = gbm.predict(test_X)\n",
    "submission = pd.DataFrame(np.vstack([test_df['Id'].values,prediction]).T, columns = ['Id','Sales'])\n",
    "\n",
    "submission['Sales'][test_df['Open'] == 0] = 0\n",
    "submission.to_csv('submission1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Simple Regression\n",
    "\n",
    "\n",
    "# param_test1 = {'alpha':[0.5, 0.8, 1, 2 , 3]}\n",
    "# gsearch1 = GridSearchCV(Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,normalize=True, solver='auto', tol=0.001), param_grid = param_test1,n_jobs=1,iid=False, cv=5)\n",
    "# gsearch1.fit(train_X,train_Y)\n",
    "# bp = gsearch1.best_params_\n",
    "# print bp\n",
    "LR = Ridge(alpha=bp['alpha'], copy_X=True, fit_intercept=True, max_iter=None,normalize=True, solver='auto', tol=0.001).fit(train_X, train_Y)\n",
    "prediction = LR.predict(test_X)\n",
    "submission = pd.DataFrame(np.vstack([test_df['Id'].values,prediction]).T, columns = ['Id','Sales'])\n",
    "submission['Sales'][test_df['Open'] == 0] = 0\n",
    "submission.to_csv('submission1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ridge Regression per group\n",
    "test_X['Id'] = test_df['Id']\n",
    "train_X['Id'] = 0\n",
    "train_X['Y'] = train_Y\n",
    "test_X['Y'] = 1\n",
    "test_X['Test'] = 1\n",
    "train_X['Test'] = 0\n",
    "\n",
    "Big_X = train_X.append(test_X)\n",
    "grouped = Big_X.groupby(['Store'])\n",
    "\n",
    "def regression_group(group):\n",
    "    G = group.groupby(['Test'])\n",
    "    try :\n",
    "        testX = G.get_group(1)\n",
    "    except :\n",
    "        return pd.DataFrame(columns = ['Id','Sales'])\n",
    "    trainX = G.get_group(0)\n",
    "    ID = testX['Id']\n",
    "    trainY = trainX['Y']\n",
    "    trainX = trainX[[col for col in trainX.columns if col not in ['Id','Test','Y']]]\n",
    "    testX = testX[[col for col in testX.columns if col not in ['Id','Test','Y']]]\n",
    "    LR = Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,normalize=True, solver='auto', tol=0.001).fit(trainX, trainY)\n",
    "    prediction = LR.predict(testX)\n",
    "    return pd.DataFrame(np.vstack([ID.values, prediction]).T, columns = ['Id','Sales'])\n",
    "\n",
    "\n",
    "def xgb_group(group):\n",
    "    G = group.groupby(['Test'])\n",
    "    try :\n",
    "        testX = G.get_group(1)\n",
    "    except :\n",
    "        return pd.DataFrame(columns = ['Id','Sales'])\n",
    "    trainX = G.get_group(0)\n",
    "    ID = testX['Id']\n",
    "    trainY = trainX['Y']\n",
    "    trainX = trainX[[col for col in trainX.columns if col not in ['Id','Test','Y']]]\n",
    "    testX = testX[[col for col in testX.columns if col not in ['Id','Test','Y']]]\n",
    "    gbm = xgb.XGBRegressor().fit(trainX, trainY)\n",
    "    prediction = gbm.predict(testX)\n",
    "    return pd.DataFrame(np.vstack([ID.values, prediction]).T, columns = ['Id','Sales'])\n",
    "                        \n",
    "data = grouped.apply(regression_group).reset_index()\n",
    "\n",
    "data_xgb = grouped.apply(xgb_group).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = data[['Id','Sales']]\n",
    "predicted.to_csv('submission_separate.csv') # 0.17685\n",
    "predicted_xgb = data_xgb[['Id','Sales']]\n",
    "predicted_xgb.to_csv('submission_separate_xgb.csv') #0.13998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combo_LR_xgb = 0.5*data.Sales + 0.5*data_xgb.Sales\n",
    "combo_LR_xgb.to_csv('LR_xgb.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def rf_group(group):\n",
    "    G = group.groupby(['Test'])\n",
    "    try :\n",
    "        testX = G.get_group(1)\n",
    "    except :\n",
    "        return pd.DataFrame(columns = ['Id','Sales'])\n",
    "    trainX = G.get_group(0)\n",
    "    ID = testX['Id']\n",
    "    trainY = trainX['Y']\n",
    "    trainX = trainX[[col for col in trainX.columns if col not in ['Id','Test','Y']]]\n",
    "    testX = testX[[col for col in testX.columns if col not in ['Id','Test','Y']]]\n",
    "    rf = RandomForestRegressor(n_estimators=200,max_depth=5).fit(trainX, trainY)\n",
    "    prediction = rf.predict(testX)\n",
    "    return pd.DataFrame(np.vstack([ID.values, prediction]).T, columns = ['Id','Sales'])\n",
    "                        \n",
    "data_rf = grouped.apply(rf_group).reset_index()\n",
    "predicted_rf = data_rf[['Id','Sales']]\n",
    "predicted_rf.to_csv('submission_separate_rf200.csv') \n",
    "#0.15431 with 200\n",
    "# 0.14689 with 50 and max depth 5\n",
    "# 0.14662 with 100 and max depth 5\n",
    "# 0.14671 with 200 and max depth 5\n",
    "# 0.14804 with 100 and max depth 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
